{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8b7ce8d",
   "metadata": {},
   "source": [
    "# Data Science Basics with NumPy, Pandas, and MatPlotLib\n",
    "\n",
    "Here will go over the basics of working datasets using the Python libraries NumPy and Pandas. We will also utilize MatPlotLib for plotting purposes to visualize data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76431a4",
   "metadata": {},
   "source": [
    "## Loading Modules/Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9723ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1:\n",
    "import time\n",
    "time.sleep(0.1)  # Sleep for 0.1 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1dcf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2:\n",
    "from time import sleep\n",
    "sleep(0.1)  # Sleep for 0.1 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff30bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3:\n",
    "import time as t\n",
    "t.sleep(0.1)  # Sleep for 0.1 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T:\n",
    "from time import *\n",
    "sleep(0.1)  # Sleep for 0.1 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abde114",
   "metadata": {},
   "source": [
    "## NumPy Basics\n",
    "\n",
    "NumPy is a crucial library in the Python ecosystem because it handles data arrays very rapidly. This is due to the fact that the NumPy backend is written in C, and therefore does array operations at a similar speed as machine-level code implementations.\n",
    "\n",
    "Unlike Matlab, Python requires the installation and import of NumPy to handle array-like data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "# Matrix addition with nested loops\n",
    "# Matrix size\n",
    "N = 5000\n",
    "\n",
    "A = [[random.random() for _ in range(N)] for _ in range(N)]\n",
    "B = [[random.random() for _ in range(N)] for _ in range(N)]\n",
    "\n",
    "C = [[0.0 for _ in range(N)] for _ in range(N)]\n",
    "\n",
    "start = time.time()\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        C[i][j] = A[i][j] + B[i][j]\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time to add two {N}x{N} matrices (pure nested Python lists): {round(end - start, 4)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0945533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A_np = np.random.rand(N, N)\n",
    "B_np = np.random.rand(N, N)\n",
    "\n",
    "start = time.time()\n",
    "C_np = A_np + B_np\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time to add two {N}x{N} matrices (with NumPy arrays): {round(end - start, 4)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e941c2d",
   "metadata": {},
   "source": [
    "### Creating Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed28723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Python list\n",
    "arr1 = np.array([1, 2, 3])\n",
    "print(\"From list:\", arr1)\n",
    "\n",
    "# Zeros and ones\n",
    "arr2 = np.zeros((2, 3))  # (rows, columns)\n",
    "arr3 = np.ones((3, 3))\n",
    "arr4 = np.full((2, 2), 17.5)\n",
    "print(\"Zeros:\\n\", arr2)\n",
    "print(\"Ones:\\n\", arr3)\n",
    "print(\"Full of 17.5s:\\n\", arr4)\n",
    "\n",
    "# Range and linspace\n",
    "arr5 = np.arange(0, 10, 2)  # integer, analogous to range() function\n",
    "arr6 = np.linspace(0, 1, 5)  # floats\n",
    "print(\"arange:\", arr5)\n",
    "print(\"linspace:\", arr6)\n",
    "\n",
    "# Random\n",
    "arr7 = np.random.rand(2, 2)  # uniform [0, 1)\n",
    "arr8 = np.random.randint(0, 10, (3, 3))\n",
    "print(\"Random floats:\\n\", arr7)\n",
    "print(\"Random ints:\\n\", arr8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027a0a5",
   "metadata": {},
   "source": [
    "### Accessing Array Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe95232",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randint(0, 10, (2, 3))\n",
    "print(\"Array:\\n\", arr)\n",
    "print(\"Shape:\", arr.shape)\n",
    "print(\"Dimensions:\", arr.ndim)\n",
    "print(\"Size:\", arr.size)\n",
    "print(\"Data type:\", arr.dtype)\n",
    "print(\"Item size (bytes):\", arr.itemsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0c4d93",
   "metadata": {},
   "source": [
    "### Indexing and Slicing in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5038d213",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[10, 20, 30], [40, 50, 60], [70, 80, 90]])\n",
    "print(\"Array:\\n\", arr)\n",
    "\n",
    "print(\"Single element [0, 1]:\", arr[0, 1])\n",
    "print(\"First column:\", arr[:, 0])\n",
    "print(\"First row:\", arr[0, :])\n",
    "print(\"Rows 1-2, all cols:\\n\", arr[1:3, :])\n",
    "print(\"Boolean indexing >50:\", arr[arr > 50])\n",
    "print(\"Fancy indexing [0, 2] rows and [1, 2] cols:\", arr[[0, 2], [1, 2]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728aef6b",
   "metadata": {},
   "source": [
    "### Element-wise Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0325f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(\"Original:\\n\", arr)\n",
    "print(\"Squared:\\n\", arr**2)\n",
    "print(\"Square root:\\n\", np.sqrt(arr))\n",
    "print(\"Exponential:\\n\", np.exp(arr))\n",
    "print(\"Logarithm:\\n\", np.log(arr))\n",
    "# other functions: np.sin, np.cos, np.tan, np.abs, np.ceil, np.floor\n",
    "\n",
    "# Element-wise operations with two arrays of the same shape\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([[5, 6], [7, 8]])\n",
    "print(\"a + b:\\n\", a + b)\n",
    "print(\"a - b:\\n\", a - b)\n",
    "print(\"a * b:\\n\", a * b)\n",
    "print(\"a / b:\\n\", a / b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0589eac2",
   "metadata": {},
   "source": [
    "### Aggregations of NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67acca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"Array:\\n\", arr)\n",
    "\n",
    "print(\"Sum over entire array\", arr.sum())\n",
    "print(\"Sum over columns:\", arr.sum(axis=0))\n",
    "print(\"Sum over rows:\", arr.sum(axis=1))\n",
    "print(\"Mean:\", arr.mean())\n",
    "print(\"Std:\", arr.std())\n",
    "print(\"Min:\", arr.min())\n",
    "print(\"Max:\", arr.max())\n",
    "print(\"Argmin:\", arr.argmin())  # index of min element of flattened array\n",
    "print(\"Argmax:\", arr.argmax())  # index of max element of flattened array\n",
    "print(\"Argmin along axis 0 (columns):\", arr.argmin(axis=0))  # indices of min elements in each column\n",
    "print(\"Argmax along axis 1 (rows):\", arr.argmax(axis=1))  # indices of max elements in each row\n",
    "\n",
    "print(\"Sum along axis 0 (columns):\", arr.sum(axis=0))\n",
    "print(\"Mean along axis 1 (rows):\", arr.mean(axis=1))\n",
    "\n",
    "# Get row/column indices of max/min elements\n",
    "row_indices, col_indices = np.unravel_index(arr.argmax(), arr.shape)\n",
    "print(f\"Row and column indices of max element: ({row_indices}, {col_indices})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c091a3c",
   "metadata": {},
   "source": [
    "### Reshaping and Combining Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e9b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(6)\n",
    "print(\"Original:\", arr)\n",
    "\n",
    "reshaped = arr.reshape(3, 2)\n",
    "print(\"Reshaped (3x2):\\n\", reshaped)\n",
    "\n",
    "flat = reshaped.flatten()\n",
    "print(\"Flattened:\", flat)\n",
    "\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([[5, 6]])\n",
    "c = np.array([[7], [8]])\n",
    "print(\"Array a:\\n\", a)\n",
    "print(\"Array b:\\n\", b)\n",
    "print(\"Concatenate:\\n\", np.concatenate([a, b], axis=0))\n",
    "print(\"Vertical stack:\\n\", np.vstack([a, b]))\n",
    "print(\"Horizontal stack:\\n\", np.hstack([a, c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b0631a",
   "metadata": {},
   "source": [
    "### Linear Algebra Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3980df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "print(\"Matrix A:\\n\", A)\n",
    "print(\"Matrix B:\\n\", B)\n",
    "\n",
    "print(\"Dot product:\\n\", np.dot(A, B))\n",
    "print(\"Using @ operator:\\n\", A @ B)\n",
    "print(\"Transpose:\\n\", A.T)\n",
    "\n",
    "print(\"Inverse:\\n\", np.linalg.inv(A))\n",
    "print(\"Determinant:\", np.linalg.det(A))\n",
    "eigvals, eigvecs = np.linalg.eig(A)\n",
    "print(\"Eigenvalues:\", eigvals)\n",
    "print(\"Eigenvectors:\\n\", eigvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ae1cd",
   "metadata": {},
   "source": [
    "### Exercise 4.1\n",
    "\n",
    "You are given measurements of thermal conductivity (in W/mK) of 3 different alloys, each measured at 5 different temperatures.\n",
    "\n",
    "Determine:\n",
    "\n",
    "- The overall maximum value and its row/column location (use `np.argmax` + `np.unravel_index`).\n",
    "\n",
    "- The minimum conductivity for each column (temperature).\n",
    "\n",
    "- The row index of the alloy with the highest average conductivity.\n",
    "\n",
    "- Compute the relative drop in conductivity (in %) for each alloy from its first to its last measurement.\n",
    "\n",
    "- Find all conductivity values greater than 170 using boolean indexing.\n",
    "\n",
    "- Suppose you want to compute a weighted average conductivity for each alloy, where the weights represent the relative importance of each temperature. Use matrix multiplication to compute the weighted conductivity values (1 per alloy) and find which alloy has the highest weighted conductivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39cb5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    [200, 190, 185, 180, 178],   # Alloy A\n",
    "    [150, 148, 147, 145, 144],   # Alloy B\n",
    "    [100,  98,  95,  92,  90]    # Alloy C\n",
    "])\n",
    "weights = np.array([0.1, 0.2, 0.3, 0.2, 0.2])  # weights for each temperature\n",
    "\n",
    "# Your code below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550bcb81",
   "metadata": {},
   "source": [
    "## Working with Data in Pandas\n",
    "Pandas is built on top of NumPy and provides high-level data structures and functions designed to make data analysis fast and easy in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a218de38",
   "metadata": {},
   "source": [
    "### Creating Pandas Objects and Inspecting Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Series\n",
    "s = pd.Series([10, 20, 30], index=[\"a\", \"b\", \"c\"])\n",
    "print(s)\n",
    "\n",
    "# DataFrame\n",
    "df = pd.DataFrame({\"A\": [1.2, 2.7, 3.1], \"B\": [4.9, 5.7, 6.2]}, index=[\"x\", \"y\", \"z\"])\n",
    "print(df)\n",
    "\n",
    "print(\"\\nInspecting DataFrame:\\n\", df)\n",
    "print(df.head())  # first few rows\n",
    "print(df.tail())  # last few rows\n",
    "\n",
    "print(\"\\nInfo and describe:\")\n",
    "print(df.info())\n",
    "print(df.describe().round(2))  # statistical summary rounded to 2 decimals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e695f1",
   "metadata": {},
   "source": [
    "### Selecting Data\n",
    "\n",
    "Selecting/slicing of data in Pandas is slightly confusing, as there are various approaches which each have their own benefits/drawbacks.\n",
    "\n",
    "| Method | Based on   | Supports arrays/slices | Slice end inclusive? | Can assign new indices? | Speed | Example |\n",
    "|--------|------------|-------------------------|----------------------|---------------------------------|-------|---------|\n",
    "| **loc**  | Labels     | ✅ Yes (slices, boolean arrays) | ✅ Yes (end label included) | ✅ Yes | Normal | `df.loc[\"r1\":\"r3\", \"col\"] = 3` |\n",
    "| **iloc** | Positions  | ✅ Yes (slices, ranges) | ❌ No (end excluded) | ❌ No  | Normal | `df.iloc[:3, 2:4] = 3` |\n",
    "| **at**   | Labels     | ❌ No (scalar only)     | N/A                  | ✅ Yes | Faster than loc | `df.at[\"C\", \"col\"] = 3` |\n",
    "| **iat**  | Positions  | ❌ No (scalar only)     | N/A                  | ❌ No  | Faster than iloc | `df.iat[2, 1] = 3` |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8d30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]}, index=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "# Column selection\n",
    "print(df[\"A\"])\n",
    "print(df.A)  # Same result, but not recommended if column name has spaces or conflicts with DataFrame methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]}, index=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "# iloc (by position)\n",
    "print(f\"\\nselect element at row 0 and 1, col 1:\\n{df.iloc[0:2, 1]}\")\n",
    "print(f\"same as above but accesssing col 1 by label:\\n{df.iloc[0:2, df.columns.get_loc('B')]}\")\n",
    "# Cannot assign new columns with iloc\n",
    "\n",
    "# loc (by labels)\n",
    "print(f'\\nselect row \"y\", col \"B\":\\n{df.loc[\"y\", \"A\":\"B\"]}')  # Careful, loc is end-inclusive!\n",
    "print(f\"same as above but accessing row 'y' by position:\\n{df.loc[df.index[1], 'A':'B']}\")\n",
    "print(f\"selecting with a boolean mask:\\n{df.loc[df['A'] > 1, :]}\")\n",
    "df.loc[:, 'C'] = [7, 8, 9]\n",
    "print(\"Can assign new columns with loc:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be6d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6], \"C\": [7, 8, 9]}, index=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "# iat (faster than iloc but only for single element)\n",
    "print(f\"\\nselect element at row 2, col 0: {df.iat[2, 0]}\") \n",
    "print(f\"same as above but accessing row 2 by label: {df.iat[df.index.get_loc('z'), 0]}\")\n",
    "# Cannot assign new columns with iat\n",
    "\n",
    "# at (faster than loc but only for single element)\n",
    "print(f'\\nselect element at row \"z\", col \"B\": {df.at[\"z\", \"B\"]}') \n",
    "print(f\"same as above but accessing col 'B' by position: {df.at['z', df.columns[1]]}\")\n",
    "df.at['z', 'D'] = 10\n",
    "print(\"\\nCan assign new columns with at:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5c724b",
   "metadata": {},
   "source": [
    "### Speed Comparison `iat` vs. `iloc` vs. applying a Lamda Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056a14ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Create a big DataFrame\n",
    "N = 100_000\n",
    "df = pd.DataFrame({\n",
    "    \"A\": np.random.randint(0, 100, N),\n",
    "    \"B\": np.random.randint(0, 100, N)\n",
    "}, dtype=np.int32)\n",
    "\n",
    "# Copy original for fairness\n",
    "df_iat = df.copy()\n",
    "df_iloc = df.copy()\n",
    "df_apply = df.copy()\n",
    "\n",
    "# --- iat (in-place, scalar access) ---\n",
    "start = time.time()\n",
    "for i in range(N):\n",
    "    df_iat.iat[i, 0] = df_iat.iat[i, 0] ** 2\n",
    "end = time.time()\n",
    "print(f\"iat inplace: {end - start:.4f} seconds\")\n",
    "\n",
    "# --- iloc (in-place, scalar access) ---\n",
    "start = time.time()\n",
    "for i in range(N):\n",
    "    df_iloc.iloc[i, 0] = df_iloc.iloc[i, 0] ** 2\n",
    "end = time.time()\n",
    "print(f\"iloc inplace: {end - start:.4f} seconds\")\n",
    "\n",
    "# --- apply (column-wise, vectorized-ish, inplace) ---\n",
    "start = time.time()\n",
    "df_apply[\"A\"] = df_apply[\"A\"].apply(lambda x: x**2)\n",
    "end = time.time()\n",
    "print(f\"apply inplace: {end - start:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744fa9f2",
   "metadata": {},
   "source": [
    "### Common Pandas Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e592be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6], \"C\": [7, 8, 9]}, index=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "print(df.mean(axis=0))  # mean of each column\n",
    "print(df.mean(axis=1))  # mean of each row\n",
    "print(df.std())   # std of each column\n",
    "print(df.median())  # median of each column\n",
    "print(df > 1)  # boolean mask\n",
    "print(df[df[\"A\"] > 1])  # rows where column A > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd65199",
   "metadata": {},
   "source": [
    "### Grouping and Method Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39838648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({\n",
    "    \"Material\": [\"Steel\", \"Steel\", \"Aluminum\", \"Aluminum\"],\n",
    "    \"Strength\": [400, 420, 150, 160],\n",
    "    \"Density\": [7.8, 7.9, 2.7, 2.8]\n",
    "})\n",
    "df3_copy = df3.copy()\n",
    "\n",
    "print(df3)\n",
    "print(df3.groupby(\"Material\").mean().round(1).reset_index())  # Method chaining\n",
    "\n",
    "# Same as:\n",
    "grouped = df3_copy.groupby(\"Material\")\n",
    "mean_df = grouped.mean()\n",
    "rounded_df = mean_df.round(1)\n",
    "final_df = rounded_df.reset_index()\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0728d76c",
   "metadata": {},
   "source": [
    "### Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea324e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({\"A\": [1, np.nan, 3], \"B\": [4, 5, np.nan]})\n",
    "print(\"Original dataframe:\\n\", df4)\n",
    "print(\"\\nFill NaN with zeros:\\n\", df4.fillna(0))\n",
    "print(\"\\nDrop all NaNs:\\n\", df4.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff6ab07",
   "metadata": {},
   "source": [
    "## Common Data File Formats for Storage\n",
    "\n",
    "| Format | Structure | Human-readable | Loading speed | Strengths | Limitations |\n",
    "|--------|-----------|----------------|---------------|-----------|-------------|\n",
    "| **CSV** (Comma-Separated Values) | Rows and columns separated by delimiters (flat, tabular) | ✅ Yes | ⚡ Medium | Simple, lightweight, works well with spreadsheets | No nested structures, no data types (all text) |\n",
    "| **JSON** (JavaScript Object Notation) | Key–value pairs, lists, nested objects (hierarchical) | ✅ Yes | 🐢 Slow | Handles complex data, preserves data types, widely used in APIs (Application Programming Interfaces) | More verbose, harder to edit manually than CSV |\n",
    "| **HDF5** (Hierarchical Data Format) | Binary format with hierarchical groups and datasets | ❌ No | ⚡ Fast | Efficient for very large datasets, supports metadata | Requires special libraries (e.g., h5py, PyTables) |\n",
    "| **Pickle** | Python-specific serialized objects | ❌ No | ⚡ Fast | Can store almost any Python object easily | Not portable outside Python, unsafe if source is untrusted |\n",
    "| **YAML** (YAML Ain’t Markup Language) | Human-readable key–value and nested structure | ✅ Yes | 🐢 Slow | More flexible and readable than JSON, allows comments | Less standardized than JSON |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76896dec",
   "metadata": {},
   "source": [
    "### Exercise 4.2, Part 1\n",
    "We’ll be working with a band gap dataset first compiled in 1973 by two scientists, W.H. Strehlow and E.L. Cook. They collected values for many elementary and binary compound semiconductors from over 700 scientific papers. Importantly, they didn’t just list numbers, they also flagged which data points are more or less reliable, based on things like the measurement method, material quality, and experimental conditions. The unedited dataset can be found [here](https://citrination.com/datasets/1160/show_files/) and its usage for teaching purposes was inspired by Prof. Dane Morgan.\n",
    "\n",
    "First load the dataset `band_gap_data.json` with the `read_json` method in Pandas and get basic information about the dataset with the previous functions we introduced. What kind of overall information would be useful when first looking at a new dataset?\n",
    "\n",
    "Then look at all unique entries of columns \"crystallinity\", \"band_gap_units\", \"band_gap_type\", \"exp_method\", and \"data_type\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9780299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f201e368",
   "metadata": {},
   "source": [
    "### Exercise 4.2, Part 2\n",
    "\n",
    "Now create separate Pandas DataFrames for polycrystalline, single crystalline, and amorphous materials (use a boolean mask).\n",
    "\n",
    "Obtain statistics for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b615564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172ce52b",
   "metadata": {},
   "source": [
    "## Plotting Data with Pandas and Matplotlib\n",
    "\n",
    "Often times visuals say more than \"just numbers\". Luckily, there are several Python libraries that are dedicated for plotting and visualization of data. Matplotlib is probably the most known one and works natively with NumPy and Pandas data structures. More recent libraries are [Seaborn](https://seaborn.pydata.org/) and [Plotly](https://plotly.com/).\n",
    "\n",
    "Matplotlib is already a quite powerful library with numerous options. We will just briefly give an example and use it to plot the information from the previous exercise. For full documentation, please have a look [here](https://matplotlib.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eafe2d",
   "metadata": {},
   "source": [
    "### Matplotlib Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b67f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data: synthetic stress-strain curve\n",
    "strain = np.linspace(0, 0.3, 100)\n",
    "stress = 200 * strain - 500 * strain**2  # toy model\n",
    "\n",
    "# Create a figure with two subplots (1 row, 2 columns)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "# --- Left subplot: stress-strain curve ---\n",
    "ax1.plot(strain, stress, color=\"blue\", label=\"Stress-Strain\")\n",
    "ax1.scatter(strain[::10], stress[::10], color=\"red\", zorder=5, label=\"Sample points\")\n",
    "ax1.set_xlabel(\"Strain\")\n",
    "ax1.set_ylabel(\"Stress (MPa)\")\n",
    "ax1.set_title(\"Stress-Strain Curve\")\n",
    "ax1.axhline(0, color=\"black\", linewidth=0.8)\n",
    "ax1.legend()\n",
    "\n",
    "# --- Right subplot: histogram of stress values ---\n",
    "ax2.hist(stress, bins=15, color=\"skyblue\", edgecolor=\"black\")\n",
    "ax2.set_xlabel(\"Stress (MPa)\")\n",
    "ax2.set_ylabel(\"Frequency\")\n",
    "ax2.set_title(\"Distribution of Stress Values\")\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and show\n",
    "fig.savefig(\"stress_analysis.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88b13f6",
   "metadata": {},
   "source": [
    "### Exercise 4.3\n",
    "\n",
    "Create a plot with three subplots: A histogram of the band gap for each polycrystalline, single crystalline, and amorphous materials from exercise 4.2.\n",
    "\n",
    "Use the `hist` function and set `density=True` to get the bin sizes relative to the total. Documentation of that function is [here](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html).\n",
    "\n",
    "- Add a horizontal line with the average value for each group.\n",
    "- Add axis labeles.\n",
    "- Add a title for each subplot.\n",
    "- Constraint the x-axis to 0-10 eV for all plots. (`set_xlim(0, 10)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e1fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f04ae",
   "metadata": {},
   "source": [
    "## Remark: Type-hinting of NumPy Arrays and Pandas DataFrames and Series\n",
    "\n",
    "For NumPy this requires the import of the numpy.typing module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f58079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.typing as npt\n",
    "\n",
    "arr: npt.NDArray[np.float64] = np.array([1.0, 2.0, 3.0])\n",
    "\n",
    "df: pd.DataFrame = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6], \"C\": [7, 8, 9]})\n",
    "series: pd.Series = pd.Series([10, 20, 30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chme6320",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
